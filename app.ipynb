{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7a19ad",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bce1d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.1.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.4.33)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.4.33)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (4.25.6)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (8.26.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (3.0.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\iam_u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\iam_u\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python ipywidgets tqdm numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1de0f",
   "metadata": {},
   "source": [
    "# Body Type Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e065e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press SPACE to capture the photo.\n",
      "Press ESC to exit without capturing.\n",
      "Image captured and saved as captured_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Iam_U\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Body Type: Fit\n",
      "Annotated image saved as 'annotated_image.jpg'.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def take_photo(filename='captured_image.jpg'):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "    \n",
    "    print(\"Press SPACE to capture the photo.\")\n",
    "    print(\"Press ESC to exit without capturing.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        cv2.imshow('Press SPACE to capture', frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        \n",
    "        if key % 256 == 27:  # ESC\n",
    "            print(\"Escape hit, closing...\")\n",
    "            frame = None\n",
    "            break\n",
    "        elif key % 256 == 32:  # SPACE\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"Image captured and saved as {filename}\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frame\n",
    "\n",
    "def detect_body_type(image):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    with mp_pose.Pose(static_image_mode=True) as pose:\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "    if not results.pose_landmarks:\n",
    "        return \"Unknown\", None\n",
    "\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "    left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "    right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
    "\n",
    "    shoulder_width = abs(left_shoulder.x - right_shoulder.x)\n",
    "    hip_width = abs(left_hip.x - right_hip.x)\n",
    "\n",
    "    ratio = shoulder_width / hip_width\n",
    "\n",
    "    # Draw landmarks on the image\n",
    "    annotated_image = image.copy()\n",
    "    mp_drawing.draw_landmarks(\n",
    "        annotated_image,\n",
    "        results.pose_landmarks,\n",
    "        mp_pose.POSE_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "        mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "    )\n",
    "\n",
    "    if ratio > 1.2:\n",
    "        return \"Fit\", annotated_image\n",
    "    elif ratio > 0.9:\n",
    "        return \"Thin\", annotated_image\n",
    "    elif ratio > 0.7:\n",
    "        return \"Fat\", annotated_image\n",
    "    else:\n",
    "        return \"Obese\", annotated_image\n",
    "\n",
    "# Run the whole thing\n",
    "frame = take_photo()\n",
    "\n",
    "if frame is not None:\n",
    "    body_type, annotated_frame = detect_body_type(frame)\n",
    "    print(f\"Detected Body Type: {body_type}\")\n",
    "    \n",
    "    if annotated_frame is not None:\n",
    "        cv2.imshow('Pose Landmarks', annotated_frame)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # Save the annotated image\n",
    "        cv2.imwrite('annotated_image.jpg', annotated_frame)\n",
    "        print(\"Annotated image saved as 'annotated_image.jpg'.\")\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No image captured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e039ba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Exercises for Fit: ['Pushups', 'Plank', 'Pullups']\n"
     ]
    }
   ],
   "source": [
    "# Exercise map based on body type\n",
    "exercise_map = {\n",
    "    'Thin': ['Pushups', 'Burpees', 'Squats'],\n",
    "    'Fit': ['Pushups', 'Plank', 'Pullups'],\n",
    "    'Fat': ['Seated Bicep Curls', 'Wall Pushups'],\n",
    "    'Obese': ['Chair Squats', 'Wall Pushups']\n",
    "}\n",
    "\n",
    "# Assuming `body_type` is detected already from the previous part of your code\n",
    "# Example usage:\n",
    "# body_type = \"Fit\"  # For example, this could be the result from `detect_body_type`\n",
    "\n",
    "# Get the suggested exercises based on body type\n",
    "suggested_exercises = exercise_map.get(body_type, [])\n",
    "print(f\"Suggested Exercises for {body_type}: {suggested_exercises}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a910f",
   "metadata": {},
   "source": [
    "# Exercise Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e58a292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Exercise: Pushups\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "# Exercise map based on body type\n",
    "exercise_map = {\n",
    "    'Thin': ['Pushups', 'Burpees', 'Squats'],\n",
    "    'Fit': ['Pushups', 'Plank', 'Pullups'],\n",
    "    'Fat': ['Seated Bicep Curls', 'Wall Pushups'],\n",
    "    'Obese': ['Chair Squats', 'Wall Pushups']\n",
    "}\n",
    "\n",
    "# Assuming `body_type` is detected already from the previous part of your code\n",
    "body_type = \"Fit\"  # Example: this could be the result from `detect_body_type`\n",
    "\n",
    "# Get suggested exercises for the detected body type\n",
    "suggested_exercises = exercise_map.get(body_type, [])\n",
    "\n",
    "# Function to get the selected exercise\n",
    "def get_selected_exercise():\n",
    "    selected_exercise = exercise_choice.get()\n",
    "    print(f\"Selected Exercise: {selected_exercise}\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Select Exercise\")\n",
    "\n",
    "# Create the dropdown menu\n",
    "exercise_choice = ttk.Combobox(root, values=suggested_exercises)\n",
    "exercise_choice.set(suggested_exercises[0])  # Set default value\n",
    "exercise_choice.pack(pady=20)\n",
    "\n",
    "# Create a button to get the selected exercise\n",
    "select_button = tk.Button(root, text=\"Select Exercise\", command=get_selected_exercise)\n",
    "select_button.pack(pady=10)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5d927",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c7dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting live webcam feed...\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Captured frame dimensions: (480, 640, 3)\n",
      "Exiting webcam feed...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to capture webcam frame (live in loop)\n",
    "def live_webcam_feed():\n",
    "    cap = cv2.VideoCapture(0)  # Open the webcam\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not access webcam.\")\n",
    "        return None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Capture frame\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Display the captured frame\n",
    "        cv2.imshow(\"Webcam Feed\", frame)\n",
    "\n",
    "        # Debugging: Show the frame dimensions to track the webcam status\n",
    "        print(f\"Captured frame dimensions: {frame.shape}\")\n",
    "\n",
    "        # Exit the loop if the user presses 'q'\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):  # Press 'q' to stop the webcam feed\n",
    "            print(\"Exiting webcam feed...\")\n",
    "            break\n",
    "\n",
    "    cap.release()  # Release the webcam\n",
    "    cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "\n",
    "# Start webcam feed and show captured frame\n",
    "print(\"Starting live webcam feed...\")\n",
    "live_webcam_feed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098c1ad",
   "metadata": {},
   "source": [
    "# Exercise Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18463b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting live webcam feed with push-up step-by-step detection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Iam_U\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting webcam feed...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Setup MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to calculate angle for push-up stage detection\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array([a.x, a.y])\n",
    "    b = np.array([b.x, b.y])\n",
    "    c = np.array([c.x, c.y])\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "# Push-up stage detection\n",
    "def pushup_stage(landmarks):\n",
    "    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    left_elbow = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n",
    "    left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
    "\n",
    "    angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "\n",
    "    if angle > 160:\n",
    "        return \"Up\"\n",
    "    elif angle < 90:\n",
    "        return \"Down\"\n",
    "    else:\n",
    "        return \"Transition\"\n",
    "\n",
    "# Function to capture webcam frame (live in loop)\n",
    "def live_webcam_feed():\n",
    "    cap = cv2.VideoCapture(0)  # Open the webcam\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not access webcam.\")\n",
    "        return None\n",
    "\n",
    "    expected_stage = \"Down\"  # Start with the \"Down\" stage\n",
    "    failure_counter = 0\n",
    "    max_failures = 3  # Number of failures allowed before suggesting an easier version\n",
    "    completed = False\n",
    "\n",
    "    while not completed:\n",
    "        ret, frame = cap.read()  # Capture frame\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB (required by MediaPipe Pose)\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        # Process the frame if pose landmarks are detected\n",
    "        if results.pose_landmarks:\n",
    "            # Draw landmarks\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "            # Detect push-up stage\n",
    "            current_stage = pushup_stage(results.pose_landmarks.landmark)\n",
    "\n",
    "            # Display the detected stage\n",
    "            cv2.putText(frame, f\"Detected: {current_stage}\", (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "\n",
    "            # Feedback and progression logic\n",
    "            if current_stage == expected_stage:\n",
    "                cv2.putText(frame, \"Step passed!\", (30, 100),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "                failure_counter = 0\n",
    "                expected_stage = \"Up\" if expected_stage == \"Down\" else \"Down\"  # Switch stages\n",
    "            else:\n",
    "                failure_counter += 1\n",
    "                cv2.putText(frame, f\"Failure {failure_counter}\", (30, 150),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "            if failure_counter >= max_failures:\n",
    "                cv2.putText(frame, \"Try an easier version!\", (30, 200),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "                completed = False  # End the session after too many failures\n",
    "\n",
    "        else:\n",
    "            # In case no person is detected\n",
    "            cv2.putText(frame, \"No Person Detected\", (30, 150),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "        # Display the frame with annotations\n",
    "        cv2.imshow(\"Webcam Feed with Push-up Detection\", frame)\n",
    "\n",
    "        # Exit the loop if the user presses 'q' (Allow user to quit at any time)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):  # Press 'q' to stop the webcam feed\n",
    "            print(\"Exiting webcam feed...\")\n",
    "            break\n",
    "\n",
    "    cap.release()  # Release the webcam\n",
    "    cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "\n",
    "# Start webcam feed and show captured frame with pose detection\n",
    "print(\"Starting live webcam feed with push-up step-by-step detection...\")\n",
    "live_webcam_feed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7568f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting live webcam feed with push-up step-by-step detection...\n",
      "Exiting webcam feed...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Setup MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to calculate angle for push-up stage detection\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array([a.x, a.y])\n",
    "    b = np.array([b.x, b.y])\n",
    "    c = np.array([c.x, c.y])\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "# Push-up stage detection\n",
    "def pushup_stage(landmarks):\n",
    "    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    left_elbow = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n",
    "    left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
    "\n",
    "    angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "\n",
    "    if angle > 160:\n",
    "        return \"Up\"\n",
    "    elif angle < 90:\n",
    "        return \"Down\"\n",
    "    else:\n",
    "        return \"Transition\"\n",
    "\n",
    "# Function to capture webcam frame (live in loop)\n",
    "def live_webcam_feed():\n",
    "    cap = cv2.VideoCapture(0)  # Open the webcam\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not access webcam.\")\n",
    "        return None\n",
    "\n",
    "    expected_stage = \"Down\"  # Start with the \"Down\" stage\n",
    "    failure_counter = 0\n",
    "    max_failures = 3  # Number of failures allowed before suggesting an easier version\n",
    "    completed = False\n",
    "    step_start_time = time.time()  # Initialize timer for the first step\n",
    "\n",
    "    while not completed:\n",
    "        ret, frame = cap.read()  # Capture frame\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB (required by MediaPipe Pose)\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        # Process the frame if pose landmarks are detected\n",
    "        if results.pose_landmarks:\n",
    "            # Draw landmarks\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "            # Detect push-up stage\n",
    "            current_stage = pushup_stage(results.pose_landmarks.landmark)\n",
    "\n",
    "            # Display the detected stage\n",
    "            cv2.putText(frame, f\"Detected: {current_stage}\", (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "\n",
    "            # Check if current stage matches the expected stage\n",
    "            if current_stage == expected_stage:\n",
    "                cv2.putText(frame, \"Step passed!\", (30, 100),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "                failure_counter = 0\n",
    "                expected_stage = \"Up\" if expected_stage == \"Down\" else \"Down\"  # Switch stages\n",
    "                step_start_time = time.time()  # Reset the timer when step is passed\n",
    "            else:\n",
    "                elapsed_time = time.time() - step_start_time\n",
    "                if elapsed_time >= 10:  # 10 seconds window expired\n",
    "                    failure_counter += 1\n",
    "                    cv2.putText(frame, f\"Failure {failure_counter}\", (30, 150),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "                    # After 3 failures, suggest easier version\n",
    "                    if failure_counter >= max_failures:\n",
    "                        cv2.putText(frame, \"Try an easier version!\", (30, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "                        completed = True  # End the session after too many failures\n",
    "                else:\n",
    "                    # Show the remaining time for the user to complete the step\n",
    "                    remaining_time = 20 - int(elapsed_time)\n",
    "                    cv2.putText(frame, f\"Time Remaining: {remaining_time}s\", (30, 150),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "        else:\n",
    "            # In case no person is detected\n",
    "            cv2.putText(frame, \"No Person Detected\", (30, 150),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "        # Display the frame with annotations\n",
    "        cv2.imshow(\"Webcam Feed with Push-up Detection\", frame)\n",
    "\n",
    "        # Exit the loop if the user presses 'q' (Allow user to quit at any time)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):  # Press 'q' to stop the webcam feed\n",
    "            print(\"Exiting webcam feed...\")\n",
    "            break\n",
    "\n",
    "    cap.release()  # Release the webcam\n",
    "    cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "\n",
    "# Start webcam feed and show captured frame with pose detection\n",
    "print(\"Starting live webcam feed with push-up step-by-step detection...\")\n",
    "live_webcam_feed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7c4a3",
   "metadata": {},
   "source": [
    "# Earlier Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "685c79b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting live webcam feed...\n",
      "Step passed!\n",
      "Failure 1\n",
      "Failure 2\n",
      "Failure 3\n",
      "Suggesting easier version: Half Pushup!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import mediapipe as mp\n",
    "\n",
    "# Setup Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Global variable to keep track of expected push-up stage\n",
    "expected_stage = \"Down\"  # Start with the \"Down\" stage\n",
    "\n",
    "# Function to capture webcam frame (live in loop)\n",
    "def live_webcam_feed():\n",
    "    global expected_stage  # Access the global expected_stage variable\n",
    "    cap = cv2.VideoCapture(0)  # Open the webcam\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not access webcam.\")\n",
    "        return None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Process the frame\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            current_stage = pushup_stage(results.pose_landmarks.landmark)\n",
    "            # Draw landmarks on the frame\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # Display detected and expected stage\n",
    "            cv2.putText(frame, f\"Detected: {current_stage}\", (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "            cv2.putText(frame, f\"Expected: {expected_stage}\", (30, 100),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "            # Logic for counting/failure detection\n",
    "            if current_stage == expected_stage:\n",
    "                print(\"Step passed!\")\n",
    "                failure_counter = 0\n",
    "                expected_stage = \"Up\" if expected_stage == \"Down\" else \"Down\"\n",
    "            else:\n",
    "                failure_counter += 1\n",
    "                print(f\"Failure {failure_counter}\")\n",
    "\n",
    "            if failure_counter >= max_failures:\n",
    "                print(\"Suggesting easier version: Half Pushup!\")\n",
    "                break\n",
    "        else:\n",
    "            current_stage = \"No Person\"\n",
    "\n",
    "        # Display the frame with annotations\n",
    "        cv2.imshow(\"Live Push-Up Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to calculate angle for push-up stage detection\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array([a.x, a.y])\n",
    "    b = np.array([b.x, b.y])\n",
    "    c = np.array([c.x, c.y])\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "# Push-up stage detection\n",
    "def pushup_stage(landmarks):\n",
    "    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    left_elbow = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n",
    "    left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
    "\n",
    "    angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "\n",
    "    if angle > 160:\n",
    "        return \"Up\"\n",
    "    elif angle < 90:\n",
    "        return \"Down\"\n",
    "    else:\n",
    "        return \"Transition\"\n",
    "\n",
    "# Main loop\n",
    "failure_counter = 0\n",
    "max_failures = 3\n",
    "\n",
    "print(\"Starting live webcam feed...\")\n",
    "live_webcam_feed()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
